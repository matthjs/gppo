agent_type: "SB_PPO"

agent_params:
  n_steps: 512
  batch_size: 256
  learning_rate: 3.56987e-05
  n_epochs: 5
  gamma: 0.95
  gae_lambda: 0.9
  clip_range: 0.3
  clip_range_vf: null
  ent_coef: 0.00238306
  vf_coef: 0.431892
  max_grad_norm: 2
  # n_envs: 1
  # n_timesteps: !!float 1e7
  # policy_kwargs:
  #   net_arch:
  #     - pi: [256, 256]
  #       vf: [256, 256]
  #   activation_fn: "relu"
  #   ortho_init: false
  #   log_std_init: -2
